{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-24 16:17:05.265208: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow import cast,float32\n",
    "from keras import backend as kb\n",
    "from statistics import mean, stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_kmer_multiple(seqlist,k):\n",
    "    kmer_list = []\n",
    "    n = -1\n",
    "    for seq in seqlist:\n",
    "        kmer_list.append(generate_kmer_single(seq,k))\n",
    "    return kmer_list\n",
    "    \n",
    "def generate_kmer_single(seq,k):\n",
    "    kmer = \"\"\n",
    "    for i in range(0,len(seq)-k,1):\n",
    "        kmer += seq[i:i+k]+\" \"\n",
    "    return kmer[:-1]\n",
    "\n",
    "def test_rmse(model,X_test,Y_test):\n",
    "    test_preds = model.predict(X_test)\n",
    "    mse = mean_squared_error(Y_test, test_preds)\n",
    "    rmse = sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    y_true = cast(y_true,float32)\n",
    "    return kb.sqrt(kb.mean(kb.square(y_pred - y_true)))\n",
    "\n",
    "def read_region(region):\n",
    "    da = pd.read_csv(\"datasets/full_length_reads.csv\")\n",
    "    file_handle = open(\"datasets/\"+region+\".fasta\",\"r\")\n",
    "    seq = []\n",
    "    seqid = []\n",
    "    tmp_seq = \"\"\n",
    "    for line in file_handle:\n",
    "        if (line[0] == \">\"):\n",
    "            if tmp_seq != \"\":\n",
    "                seq.append(tmp_seq)\n",
    "            seqid.append(line.split(\"\\n\")[0][1:])\n",
    "            tmp_seq = \"\"\n",
    "        else:\n",
    "            tmp_seq+=line.split(\"\\n\")[0]\n",
    "    seq.append(tmp_seq)\n",
    "    file_handle.close()\n",
    "    sub = pd.DataFrame([seq,seqid], index = [region,\"accession\"])\n",
    "    sub = sub.transpose()\n",
    "    da = da[[\"accession\",\"copy_number\"]]\n",
    "    da = pd.merge(da,sub,on=\"accession\",how=\"inner\")\n",
    "    return da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64,activation='relu'))\n",
    "    model.add(Dense(16,activation='relu'))\n",
    "    model.add(Dense(8,activation='relu'))\n",
    "    model.add(Dense(1,activation='linear'))\n",
    "    model.compile(loss=root_mean_squared_error,optimizer=Adam(0.001))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = read_region(\"V1_simu\")\n",
    "da.columns = [\"accession\",\"copy_number\",\"sequence\"]\n",
    "for region in [\"V2_simu\",\"V3_simu\",\"V4_simu\",\"V5_simu\",\"V6_simu\",\"V7_simu\",\"V8_simu\",\"V9_simu\"]:\n",
    "    tmp = read_region(region)\n",
    "    tmp.columns = [\"accession\",\"copy_number\",\"sequence\"]\n",
    "    da = pd.concat([da,tmp],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = da.sample(frac = 1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplicand = int(X.shape[0]*0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-24 16:18:37.331435: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-08-24 16:18:37.332864: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2794690000 Hz\n",
      "2022-08-24 16:18:37.949293: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-08-24 16:18:38.606085: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-08-24 16:18:38.606145: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8721106004840917\n",
      "0.8763050660913456\n",
      "0.9433123327178579\n",
      "0.9065184060819004\n",
      "0.8998458572473736\n"
     ]
    }
   ],
   "source": [
    "rmse = []\n",
    "for i in range(0,5,1):\n",
    "    X_test = da[\"sequence\"][i*multiplicand:(i+1)*multiplicand]\n",
    "    Y_test = da['copy_number'][i*multiplicand:(i+1)*multiplicand]\n",
    "    X_train = pd.concat([da[\"sequence\"][0:i*multiplicand],da[\"sequence\"][(i+1)*multiplicand:]],axis = 0)\n",
    "    Y_train = pd.concat([da['copy_number'][0:i*multiplicand],da['copy_number'][(i+1)*multiplicand:]],axis = 0)\n",
    "    vectorizer = CountVectorizer()\n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    X_test = pd.DataFrame(X_test)\n",
    "    X_train = X_train.values.reshape(X_train.shape[0], )\n",
    "    X_test = X_test.values.reshape(X_test.shape[0], )\n",
    "    kmer_train = generate_kmer_multiple(X_train.tolist(), 6)\n",
    "    kmer_test = generate_kmer_multiple(X_test.tolist(), 6)\n",
    "    X_train = vectorizer.fit_transform(kmer_train).toarray()\n",
    "    X_test = vectorizer.transform(kmer_test).toarray()\n",
    "    model = create_model()\n",
    "    model.fit(X_train,Y_train, validation_split= 0.1, batch_size=64,epochs=20,verbose = 0)\n",
    "    rmse.append(test_rmse(model,X_test,Y_test))\n",
    "    print(rmse[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(rmse,columns=[\"method1_self_cv\"]).to_csv(\"performance/MLP_method1_train.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1474/1474 [==============================] - 5s 3ms/step - loss: 1.1980 - val_loss: 1.0229\n",
      "Epoch 2/20\n",
      "1474/1474 [==============================] - 4s 3ms/step - loss: 0.9465 - val_loss: 0.9720\n",
      "Epoch 3/20\n",
      "1474/1474 [==============================] - 4s 3ms/step - loss: 0.8699 - val_loss: 0.9434\n",
      "Epoch 4/20\n",
      "1474/1474 [==============================] - 4s 3ms/step - loss: 0.8222 - val_loss: 0.9137\n",
      "Epoch 5/20\n",
      "1474/1474 [==============================] - 4s 3ms/step - loss: 0.7944 - val_loss: 0.9519\n",
      "Epoch 6/20\n",
      "1474/1474 [==============================] - 5s 3ms/step - loss: 0.7688 - val_loss: 0.9257\n",
      "Epoch 7/20\n",
      "1474/1474 [==============================] - 4s 3ms/step - loss: 0.7498 - val_loss: 0.8951\n",
      "Epoch 8/20\n",
      "1474/1474 [==============================] - 4s 3ms/step - loss: 0.7404 - val_loss: 0.8836\n",
      "Epoch 9/20\n",
      "1474/1474 [==============================] - 4s 3ms/step - loss: 0.7259 - val_loss: 0.9069\n",
      "Epoch 10/20\n",
      "1474/1474 [==============================] - 4s 3ms/step - loss: 0.7172 - val_loss: 0.8971\n",
      "Epoch 11/20\n",
      "1474/1474 [==============================] - 4s 3ms/step - loss: 0.7088 - val_loss: 0.8760\n",
      "Epoch 12/20\n",
      "1474/1474 [==============================] - 4s 3ms/step - loss: 0.7012 - val_loss: 0.8903\n",
      "Epoch 13/20\n",
      "1474/1474 [==============================] - 4s 3ms/step - loss: 0.6975 - val_loss: 0.8807\n",
      "Epoch 14/20\n",
      "1474/1474 [==============================] - 4s 3ms/step - loss: 0.6912 - val_loss: 0.9131\n",
      "Epoch 15/20\n",
      "1474/1474 [==============================] - 4s 3ms/step - loss: 0.6863 - val_loss: 0.8898\n",
      "Epoch 16/20\n",
      "1474/1474 [==============================] - 4s 3ms/step - loss: 0.6813 - val_loss: 0.8902\n",
      "Epoch 17/20\n",
      "1474/1474 [==============================] - 4s 3ms/step - loss: 0.6800 - val_loss: 0.8829\n",
      "Epoch 18/20\n",
      "1474/1474 [==============================] - 4s 3ms/step - loss: 0.6755 - val_loss: 0.8719\n",
      "Epoch 19/20\n",
      "1474/1474 [==============================] - 4s 3ms/step - loss: 0.6715 - val_loss: 0.8816\n",
      "Epoch 20/20\n",
      "1474/1474 [==============================] - 4s 3ms/step - loss: 0.6702 - val_loss: 0.8683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f90af1adf70>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = da[\"sequence\"]\n",
    "Y = da[\"copy_number\"]\n",
    "vectorizer = CountVectorizer(lowercase=False)\n",
    "kmer_train = generate_kmer_multiple(X.tolist(), 6)\n",
    "x = vectorizer.fit_transform(kmer_train).toarray()\n",
    "model = create_model()\n",
    "model.fit(x,Y,validation_split=0.1, batch_size=100,epochs=20,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6283952403496214\n",
      "3.9841057641193838\n",
      "2.7045830899275773\n",
      "1.0342397194012474\n",
      "3.2559326080977895\n",
      "4.27168729169467\n",
      "3.7800950255715953\n"
     ]
    }
   ],
   "source": [
    "performance = {}\n",
    "for region in [\"V1-V2\",\"V1-V3\",\"V3-V4\",\"V4\",\"V4-V5\",\"V6-V8\",\"V7-V9\"]:\n",
    "    region_da = read_region(region)\n",
    "    X = region_da[region]\n",
    "    Y = region_da['copy_number']\n",
    "    kmer_train = generate_kmer_multiple(X.tolist(), 6)\n",
    "    x = vectorizer.transform(kmer_train).toarray()\n",
    "    res = test_rmse(model,x,Y)\n",
    "    print(res)\n",
    "    performance[region] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V1-V2</td>\n",
       "      <td>2.628395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V1-V3</td>\n",
       "      <td>3.984106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V3-V4</td>\n",
       "      <td>2.704583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V4</td>\n",
       "      <td>1.03424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V4-V5</td>\n",
       "      <td>3.255933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>V6-V8</td>\n",
       "      <td>4.271687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>V7-V9</td>\n",
       "      <td>3.780095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test      rmse\n",
       "0  V1-V2  2.628395\n",
       "1  V1-V3  3.984106\n",
       "2  V3-V4  2.704583\n",
       "3     V4   1.03424\n",
       "4  V4-V5  3.255933\n",
       "5  V6-V8  4.271687\n",
       "6  V7-V9  3.780095"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([list(performance.keys()),list(performance.values())],index = [\"test\",\"rmse\"]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([list(performance.keys()),list(performance.values())],index = [\"test\",\"rmse\"]).transpose().to_csv(\"performance/MLP_method1_test.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
